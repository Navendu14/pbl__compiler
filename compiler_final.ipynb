{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95965e1-65fd-46e2-a7da-82f47647ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import multiprocessing\n",
    "import hashlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f085008-78df-434b-a1e2-9338035a145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DIR = \"temp_files\"\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58250a-4e4a-46f8-a6c4-591928f468cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"obj_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70909cd2-1a01-4b16-9b2d-2b0a83928a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: input.c converted to temp_files/input.ll\n"
     ]
    }
   ],
   "source": [
    "input_ll = os.path.join(TEMP_DIR, \"input.ll\")\n",
    "subprocess.run([\"clang\", \"-S\", \"-emit-llvm\", \"input.c\", \"-o\", input_ll], check=True)\n",
    "print(\"Step 1: input.c converted to\", input_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f21d534-728d-490a-9c61-6115a214fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Functions found: ['sum_array', 'main']\n"
     ]
    }
   ],
   "source": [
    "with open(input_ll, \"r\") as f:\n",
    "    content = f.read()\n",
    "func_names = re.findall(r\"define\\s+.*?\\s+@(\\w+)\\(\", content)\n",
    "print(\"Step 2: Functions found:\", func_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca6bc155-e305-4fb4-8528-512ac18d1795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3a: Extracted and modified temp_files/globals.ll with linkonce_odr linkage\n"
     ]
    }
   ],
   "source": [
    "with open(input_ll, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith(\"define\"):\n",
    "        break\n",
    "globals_lines = lines[:i]\n",
    "for j, line in enumerate(globals_lines):\n",
    "    if line.strip().startswith(\"@\"):\n",
    "        globals_lines[j] = line.replace(\"private\", \"linkonce_odr\")\n",
    "globals_ll = os.path.join(TEMP_DIR, \"globals.ll\")\n",
    "with open(globals_ll, \"w\") as f:\n",
    "    f.writelines(globals_lines)\n",
    "print(\"Step 3a: Extracted and modified\", globals_ll, \"with linkonce_odr linkage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17651891-6b99-47b1-a821-643fda2e035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3b: Compiled temp_files/globals.ll to temp_files/globals.o\n"
     ]
    }
   ],
   "source": [
    "globals_o = os.path.join(TEMP_DIR, \"globals.o\")\n",
    "subprocess.run([\"clang\", \"-c\", globals_ll, \"-o\", globals_o], check=True)\n",
    "print(\"Step 3b: Compiled\", globals_ll, \"to\", globals_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69f8b4a3-c330-439c-92ed-2c20e2a7377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Split input.ll into separate .ll files: ['temp_files/sum_array.ll', 'temp_files/main.ll']\n"
     ]
    }
   ],
   "source": [
    "ll_files = []\n",
    "if len(func_names) > 1:\n",
    "    for func in func_names:\n",
    "        bc_file = os.path.join(TEMP_DIR, f\"{func}.bc\")\n",
    "        ll_file = os.path.join(TEMP_DIR, f\"{func}.ll\")\n",
    "        \n",
    "        subprocess.run([\"llvm-extract\", \"-func\", func, input_ll, \"-o\", bc_file], check=True)\n",
    "        \n",
    "        subprocess.run([\"llvm-dis\", bc_file, \"-o\", ll_file], check=True)\n",
    "        \n",
    "        ll_files.append(ll_file)\n",
    "else:\n",
    "    ll_files = [input_ll]\n",
    "print(\"Step 4: Split input.ll into separate .ll files:\", ll_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34170c94-8f43-4d36-a59f-ac1dc195d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ll_code(code: str) -> str:\n",
    "    code = re.sub(r\"^\\s*;.*\", \"\", code, flags=re.MULTILINE)\n",
    "    code = re.sub(r'^\\s*source_filename\\s*=.*', '', code, flags=re.MULTILINE)\n",
    "    code = re.sub(r'^\\s*target datalayout\\s*=.*', '', code, flags=re.MULTILINE)\n",
    "    code = \"\\n\".join(line.strip() for line in code.splitlines() if line.strip())\n",
    "    \n",
    "    declares = []\n",
    "    defines = []\n",
    "    for line in code.splitlines():\n",
    "        if line.startswith(\"declare\"):\n",
    "            declares.append(line.strip())\n",
    "        else:\n",
    "            defines.append(line)\n",
    "\n",
    "    declares = sorted(declares)\n",
    "    triple_match = re.search(r'(target triple\\s*=\\s*\".*?\")', code)\n",
    "    triple_line = triple_match.group(1) if triple_match else None\n",
    "\n",
    "    normalized = []\n",
    "    if triple_line:\n",
    "        normalized.append(triple_line)\n",
    "    normalized.extend(declares)\n",
    "    normalized.extend(defines)\n",
    "\n",
    "    return \"\\n\".join(normalized)\n",
    "\n",
    "def compute_file_hash(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        code = f.read()\n",
    "    normalized_code = normalize_ll_code(code)\n",
    "    return hashlib.sha256(normalized_code.encode('utf-8')).hexdigest()\n",
    "\n",
    "def compile_to_o(ll_file):\n",
    "    file_hash = compute_file_hash(ll_file)\n",
    "    cached_obj = os.path.join(CACHE_DIR, f\"{file_hash}.o\")\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(ll_file))[0]\n",
    "    o_file = os.path.join(TEMP_DIR, f\"{base_name}.o\")\n",
    "    \n",
    "    if os.path.exists(cached_obj):\n",
    "        shutil.copyfile(cached_obj, o_file)\n",
    "        print(f\"Cache hit: {ll_file} → {o_file} (from {cached_obj})\")\n",
    "    else:\n",
    "        subprocess.run([\"clang\", \"-c\", ll_file, \"-o\", o_file], check=True)\n",
    "        print(f\"Compiled {ll_file} to {o_file}\")\n",
    "        \n",
    "        shutil.copyfile(o_file, cached_obj)\n",
    "        print(f\"Cached {o_file} as {cached_obj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15094f35-bc43-4112-8231-8908d9d1e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit: temp_files/sum_array.ll → temp_files/sum_array.o (from obj_cache/662b187106f197f08c6dfd8170281c0c2eab7b45595dbe2b7ddd5cf0ef9de5ab.o)Cache hit: temp_files/main.ll → temp_files/main.o (from obj_cache/665b93e24d74625aed9553602398572a36b2caddd559e847566b79f5fb6db346.o)\n",
      "\n",
      "Step 5: Compiled all .ll files to .o files with caching\n"
     ]
    }
   ],
   "source": [
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(compile_to_o, ll_files)\n",
    "print(\"Step 5: Compiled all .ll files to .o files with caching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87ce0ce2-af57-4dac-8a39-9f66551368e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Linked all .o files into executable 'output'\n"
     ]
    }
   ],
   "source": [
    "o_files = [os.path.join(TEMP_DIR, f\"{os.path.splitext(os.path.basename(ll_file))[0]}.o\") for ll_file in ll_files] + [globals_o]\n",
    "subprocess.run([\"clang\"] + o_files + [\"-o\", \"output\"], check=True)\n",
    "print(\"Step 6: Linked all .o files into executable 'output'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cb05707-f483-4fc3-9df7-83f04e37a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Cleaned up temporary directory temp_files\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(\"Step 7: Cleaned up temporary directory\", TEMP_DIR)\n",
    "except Exception as e:\n",
    "    print(f\"Step 7: Failed to clean up {TEMP_DIR}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f67ea8-f046-4bfb-b3ad-7da5c52427bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e4fbe-b2d1-4792-b0a2-ce7dfa457468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
